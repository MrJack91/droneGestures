\chapter{Analyse}

\section{Recherche}
\label{sec:recherche}

\subsubsection{Bezeichnung}
Der Ausdruck \gls{glos:droneLabel} kommt vom niederdeutschen Wort \textit{"`drone"'}, welches wiederum seinen Ursprung beim indogermanischen Wort \textit{"`dhren"'} findet. Die Bedeutung dieses Wortes lautet "`brummen"' oder "`dröhnen"'. \footcite{Geschichte_der_Drohne_-_Nachrichten_Print_-_DIE_WELT_-_Wissen_Print_DW_-_DIE_WELT_2015-03-21}

\begin{framed}
	\textit{Definition: }\textbf{\gls{glos:droneLabel}}\\
	Als \gls{glos:droneLabel} wird ein unbemanntes Luftfahrzeug bezeichnet. Die Steuerung kann entweder manuell oder autonom erfolgen.\\
	Quelle:
	\fullcite{Drone_Define_Drone_at_Dictionary.com_2015-03-21}
\end{framed}

\subsection{Geschichte der Drohne}

\subsubsection{Frühe Entwicklung}
Eine der allerersten bekannten \gls{glos:droneLabel} war wohl von den Brüder Mongolfier (1783) aus Frankreich, ein unbemannter Heissluftballon. \footcite{Kleine_Geschichte_der_Drohnen_-_Nachrichten_Print_-_WELT_KOMPAKT_-_Lifestyle_-_DIE_WELT_2015-03-21}
\footcite{Unbemannte_Luftfahrt__Wikipedia_2015-03-22}

\subsubsection{Waffenträger}
Später wurde das Potenzial von \glspl{glos:droneLabel} besonders für kriegerische Zwecke erforscht und entwickelt.

\begin{wrapfigure}{r}{0.4\textwidth}
	\includegraphics[width=1.0\linewidth]{images/analysis/balloonbombs1849.jpg}
 	\caption[Bombing by Balloon, 1848]{Bombing by Balloon, 1848 (Quelle: \fullcite{Remote_Piloted_Aerial_Vehicles_2015-03-21})}
\end{wrapfigure}

So wurden bereits 1849, vom österreichischen Königsreich, unbemannte Heissluftballone mit Bomben im Krieg gegen Venedig losgeschickt.
Weder die "`\gls{glos:droneLabel}"' selbst, noch das Abwerfen der Bombe konnte aktiv gesteuert werden.
Die Heissluftballone flogen mit dem Wind und die Bomben wurde per Zeitzünder gezündet. Tatsächlich erreichten einzelne Ballone ihr Ziel und konnten Schaden anrichten, andere jedoch wurden vom Wind zurück geweht und zerstörten das eigene Territorium Österreichs. \footcite{Remote_Piloted_Aerial_Vehicles_2015-03-21}

Während dem \textit{Ersten Weltkrieg} wurden die ersten unbemannten Flugzeuge von den Amerikanern entwickelt.
Mit diesen wurden vordefinierte Routen abgeflogen und es konnten \textit{Flugtorpedos} abgeworfen werden, welche wie die Flugzeuge selbst, mit Hilfe von gyroskopischen Stabilisierer und Aneroidbarometer zwar Richtung und Höhe halten konnten, jedoch nicht per Funk steuerbar waren.

Die ersten funkgesteuerten \glspl{glos:droneLabel} wurde erst nach dem Krieg 1918 fertig.
Nebst den Amerikanern, hatten auch die Briten 1925 ihren ersten Drohnenflug durchgeführt. Diese konnte etwa 300\,Meilen (ca. 483\,km) mit einer Geschwindigkeit von 190\,mph (ca. 306\,km/h) zurücklegen.\footcite{Informatik_und_Gesellschaft_2015-03-21}

Da der Krieg vorbei war, wurden die \glspl{glos:droneLabel} hauptsächlich für Jagd-Trainings der Armee genutzt.

Mit den Jahren wurden die \glspl{glos:droneLabel} immer weiter verbessert und werden heute aktiv gegen terroristische Aktivitäten verwendet.

\subsubsection{Weitere Zwecke}
% http://diepresse.com/home/politik/innenpolitik/1385181/Die-Geschichte-der-Drohnen
Nebst den erwähnten Waffenträger gibt es auch diverse weitere Aufgaben für \glspl{glos:droneLabel}: Beobachtungen (z.B. Aufklärungen, Luftaufnahmen, Wetterbeobachtungen, Filmproduktionen), Messungen an Orten die für Menschen ungeeignet oder schädlich sind oder Transporte.

Obschon viele Aufgabenbereiche gewaltfrei sind, dienen \glspl{glos:droneLabel} trotzdem mehrheitlich polizeilichen oder militärischen Organisationen.\footcite{Die_Geschichte_der_Drohnen_DiePresse.com_2015-03-21}

\subsubsection{Heutige Einsätze von Drohnen}
Seit 2013 werden, in Grand Forks County im US-Bundesstaat North Dakota, \glspl{glos:droneLabel} zur Verbrecherjagd eingesetzt, resp. zur Personensuche.

Auch Amazon kündet ihren "`\textit{Prime Air}"'-Service an, der Pakete direkt vor die Haustür liefert.

Im Jahr 2014 wurde der Einsatz für landwirtschaftliche Zwecke erprobt und auch die \gls{glos:dhlLabel} führte Testlieferungen mit \glspl{glos:droneLabel} aus. \footcite{Kleine_Geschichte_der_Drohnen_-_Nachrichten_Print_-_WELT_KOMPAKT_-_Lifestyle_-_DIE_WELT_2015-03-21}


\section{Quadrocopter}
\begin{wrapfigure}{r}{0.4\textwidth}
	\includegraphics[width=1.0\linewidth]{images/analysis/crazyflize.jpg}
	\caption[Crazyflie 2.0]{Crazyflie 2.0 (Quelle: \fullcite{Crazyflie_2.0_Seeedstudio_2015-03-22})}
\end{wrapfigure}
Der Quadrocopter eignet sich als \gls{glos:droneLabel}, da die Steuerung ausschliesslich über die vier Rotoren realisiert wird.
Weitere mechanische Steuerkomponente entfallen, was die Komplexität des Luftfahrzeuges deutlich vereinfacht.
Je zwei der Rotoren drehen in dieselbe Richtung (im bzw. gegen den Uhrzeigersinn) und stehen sich gegenüber.

Generell gilt für vorliegendes Dokument, insofern nicht anders vermerkt oder aus dem Kontext ersichtlich, dass der Begriff Drohne mit dem Begriff Quadrocopter gleichzustellen ist (davon ausgeschlossen ist \secref{sec:recherche}).

\subsection{Steuerung}
Bezüglich der Flugeigenschaften entspricht ein Quadrocopter am ehesten einem Hubschrauber und gehört ebenfalls zur Kategorie der  \gls{glos:vtolLabel}-Flugzeugen.
Es sind jegliche Steuermöglichkeiten im dreidimensionalen Raum möglich (steigen/sinken "`\textit{thrust}"', gieren/drehen "`\textit{yaw}"', nicken "`\textit{pitch}"' und rollen "`\textit{roll}"').

Durch das, dass die Rotoren in entgegengesetzte Richtungen drehen, hebt sich das auf das Traggestell übertragene Drehmoment auf und der Quadrocopter kann ohne Drehung fliegen.
Um sich nun in eine Richtung zu \textit{gieren}, werden die Drehzahlen von jeweils zwei gegenüberliegende Rotoren gleichmässig verändert, so dass der Drehmoment auf das Traggestell nicht mehr neutralisiert wird und sich so eine Drehung ergibt.

Um dem Piloten die Steuerung zu erleichtern, befinden sich oft verschiedenfarbige Markierungen oder LED's an der Vorder- oder Rückseite des Quadrocopters.
Die Steuerung erfolgt üblicherweise aus relativer Sicht der Drohne und erfordert somit ein Umdenken des Piloten.\footcite{Quadrocopter__Wikipedia_2015-03-22}


\subsection{Bereits bestehende Arbeiten}
%todo
% https://www.youtube.com/channel/UCuYdAd53adsu0nyWVg_QGKQ
% https://www.youtube.com/watch?v=4UnRtn1pgAs
% https://www.youtube.com/watch?v=XN0fHLgYWy8
\subsubsection{Steuermöglichkeiten}

\subsubsection{Sensoren Integration auf bestehende Steuerungen}

%%%
%todo correct
\section{Ist-Analyse}

\subsection{Gestensensor} \label{subsec:leapmotion}
\begin{wrapfigure}{r}{0.4\textwidth}
	\includegraphics[width=1.0\linewidth]{images/analysis/leap_simple.png}
	\caption[Leap Motion Sensor]{Leap Motion Sensor (Quelle: \fullcite{Move_Over_Kinect:_Early_Gestural_Musical_Demos_for_Leap_Motion_Look_Terrific_-_Create_Digital_Music_2015-03-27})}
\end{wrapfigure}
%too much: not used
%\begin{wrapfigure}{l}{0.4\textwidth}
%	\includegraphics[width=1.0\linewidth]{images/analysis/leap_laptop.jpg}
%	\caption[Leap Motion -- Produktbild]{Leap Motion -- Produktbild \protect\cite{Leap_Motion_Motion_Controller_2015-03-27}}
%\end{wrapfigure}

Für die Erkennung der Gesten wird der Leap Motion Sensor\footcite{Leap_Motion_Motion_Controller_2015-03-27} verwendet.
Dieser erkennt Hände (inkl. einzelne Finger) und stellt Daten derer Position, Gesten und Bewegungen zur Verfügung.

\subsubsection{Technische Details}
Die Erkennung erfolgt via optische Sensoren und Infrarot Licht.
Der Leap Motion wird per USB 2.0 angeschlossen und erkennt Gesten innerhalb eines 150\textdegree-Winkels zwischen 25\,mm und 600\,mm Höhe.
Am Besten funktioniert der Sensor, wenn die Silhouette der Hand einen hohen Kontrast zur Umgebung aufweist.
Die Messdaten werden mit einem internen Handmodell kombiniert, so dass immer eine vollständige Hand als Output vorliegt.
\footcite{API_Overview__Leap_Motion_v2.2_documentation_2015-03-27}


\begin{figure}[H]
  \IfDefined{RawFloats}{\RawFloats} % required if floatrow is loaded
  \begin{minipage}[b]{0.45\linewidth}
    \centering
   	\includegraphics[width=1.0\linewidth]{images/analysis/leap_360_view.png}
   	\caption[Leap Motion von allen Seiten]{Leap Motion von allen Seiten (Quelle: \fullcite{Leap_Motion_-_VJs_Magazine_2015-03-27})}
  \end{minipage}%
  \hspace{.1\linewidth}
  \begin{minipage}[b]{0.45\linewidth}
    \centering
	\includegraphics[width=1.0\linewidth]{images/analysis/leap_technical_specifiaction.png}
	\caption[Leap Motion -- Technische Spezifikationen]{Leap Motion -- Technische Spezifikationen (Quelle: \fullcite{Leap_Motion_Motion_Controller_2015-03-27})}
  \end{minipage}
\end{figure}

Weitere Informationen könne übersichtlich auf der Website des Herstellers\footcite{Leap_Motion_Motion_Controller_2015-03-27} gefunden werden.

\subsubsection{Anwendungsbereich}
\begin{wrapfigure}{r}{0.4\textwidth}
	\includegraphics[width=1.0\linewidth]{images/analysis/leap_vr.png}
%	\caption[Oculus Rift VR]{\gls{vrLabel} Oculus Rift (Quelle: \fullcite{Leap_Motion_Developers_2015-03-27})}
	\caption[Oculus Rift VR]{\acrshort{vrLabel} Oculus Rift (Quelle: \fullcite{Leap_Motion_Developers_2015-03-27})}
	\label{fig:leap_vr}
\end{wrapfigure}
Der Anwendungsbereich für Gestenerkennung ist beinahe grenzenlos.
Da der Leap Motion speziell für Entwickler produziert wurde, kann der Sensor für jegliche Programme oder Steuerungen verwendet werden.

Allerdings sind Gestensteuerungen für "`gewöhnliche"' Steueraufgaben nach wie vor sehr wenig verbreitet, obwohl es theoretisch nichts intuitiveres als Gesten gibt.
Dies kann unter anderem an fehlenden Anwendungsfällen oder an falsch angesetzten Umsetzungen liegen.

Im Gesten-Entwicklungsbereich gibt es nebst den "`klassischen"' Anwendungen (wie Spiele, Scrolling, Musikkontrolle etc.) viele interessante  \gls{vrLabel}-Anwendungen. Der Sensor wird, wie in \figref{fig:leap_vr} ersichtlich ist, vorne auf einer \gls{vrLabel}-Brille befestigt und ermöglicht so eine Simulation virtueller Hände, durch welche die Steuerung erfolgt.

\subsubsection{Einrichtung}
Die Installation des Leap Motion's, gemäss der offiziellen Installationsanweisungen,\footcite{Getting_Started_Leap_Motion_Developers_2015-03-28} funktionierte auf einem OS X 10.10.2 einwandfrei.
Entsprechend sollte  die Installation auch auf einem Windows 7 oder 8 erfolgreich durchgeführt werden können.

\subsubsection{API}
% sprachen
% Aufbau der Antworten
Um den Leap Motion anzusteuern werden folgende Sprachen und Frameworks angeboten:
\begin{itemize}
	\item \textbf{JavaScript:} für Node.js oder Browser Anwendungen (siehe Beispiele\footcite{Getting_Started_Leap_Motion_Developers_2015-03-28})
	\item \textbf{Unity / C\#:} 3D Anwendungen
	\item \textbf{C++:} für hardwarenahe Anwendungen
	\item \textbf{Java}
	\item \textbf{Python}
	\item \textbf{Objective-C}: für Anwendungen auf Apple OS X
\end{itemize}

Da die Drohne ebenfalls via Python programmiert werden kann, werden alle Komponenten in Python umgesetzt und es wird nur noch auf die Python-Schnittstelle\footcite{Python_SDK_Documentation__Leap_Motion_Python_SDK_v2.2_documentation_2015-03-28} detaillierter eingegangen. Das Prinzip der verfügbaren Daten ist jedoch bei allen Schnittstellen dasselbe.

Über das \gls{apiLabel} können einzelne \glspl{glos:frameLabel} mit Infos zu erkennbaren Objekten abgerufen werden.

Folgende \textbf{Objekte} stehen pro \gls{glos:frameLabel} zur Verfügung: Hände, Finger, Knochen (Arm- und Fingerknochen) und fingerähnliche Werkzeuge (z.B. Bleistifte).
Alle Objekte werden genau identifiziert, sprich die Hände werden als rechte und linke Hand erkannt, jeder Finger als richtigen Fingertyp und jeder Fingerknochen als korrekten physikalischen Knochen. Diese Erkennung funktioniert unabhängig der Position des Objektes. Dank dem Handmodell werden nicht messbare Werte angenähert.
Jedes Objekt enthält zudem einen Richtungsvektor.

Die \textbf{Veränderung} (Grösse, Drehung, Bewegung) von Objekten zwischen zwei \glspl{glos:frameLabel} kann ebenfalls abgerufen werden.

Weiter können folgende \textbf{Gesten} erkannt werden: Kneifen, Greifen, Kreisen, Wischen und Tippen.
Beim Kneifen und Greifen ist ausserdem die Stärke der Geste messbar (eins entspricht dem Maximum der möglichen Geste [z.B. einer Faust]).

\subsection{Drohne}
Die \textit{Crazyflie} gibt es momentan in zwei Versionen: als "`\textit{Crazyflie}"' und "`\textit{Crazyflie 2.0}"'. Verständlichkeitshalber wird im vorliegenden Dokument die erste Version "`\textit{Crazyflie}"' als "`\textit{Crazyflie 1.0}"' bezeichnet und der Begriff "`\textit{Crazyflie}"' wird für das Produkt allgemein (versionsunabhängig) verwendet.

Alle Informationen zur \textit{Crazyflie} sind im Wiki von Bitcraze vorhanden.\footcite{index_Bitcraze_Wiki_2015-03-29}

Versionsunabhängige Informationen zu  \textit{Clients}, \textit{Development}, \textit{Architcture}, \textit{\gls{apiLabel}}, \textit{Protocols} und \textit{Analysis} sind unter "`Crazyflie"' (allgemein) abgelegt.\footcite{doc_crazyflie_index_Bitcraze_Wiki_2015-03-29}

Versionsspezifische Daten der \textit{Crazyflie 2.0} werden separat aufgeführt.\footcite{projects_crazyflie2_index_Bitcraze_Wiki_2015-03-29}

\subsubsection{Technische Details}
% Protocol: http://wiki.bitcraze.se/doc:crazyflie:crtp:index
Hardwarespezifische Informationen und Überlegungen zur Architektur sind für die \textit{Crazyflie 1.0} ausführlich dokumentiert.\footcite{projects_crazyflie_hardware_explained_Bitcraze_Wiki_2015-03-29}
Während zur \textit{Crazyflie 2.0} die Angaben eher konzentriert und ergänzend zur Verfügung stehen.
\footcite{projects_crazyflie2_architecture_index_Bitcraze_Wiki_2015-03-29}
\footcite{projects_crazyflie2_hardware_specification_Bitcraze_Wiki_2015-03-29}

Die Drohne hat zwei Prozessoren. Einen für das Power- und Radiomanagement ("`nRF51822"') und eine für die eigentliche Steuerung ("`STM32F405"').

Die Kommunikation zwischen Client und Drohne erfolgt über das \gls{crtpLabel}, eigen von Bitcraze entwickelt.\footcite{doc_crazyflie_crtp_index_Bitcraze_Wiki_2015-03-30}

Folgende Werte können gemessen werden:
\begin{itemize}
	\item \textbf{"'MPU-9250"'}\footcite{MEMS_Gyro-Accel_Gyroscope_Accelerometer_Processing_-_MPU-9250_Nine-Axis_2015-03-30} (Gyro-, Accelero-, Magentometer)
	\begin{itemize}
		\item Der \textbf{Gyrometer} misst die Erdanziehungskraft auf alle drei Seiten. Damit kann die Position und die Abweichung festgestellt werden.
		\item Der \textbf{Accelerometer} misst die Beschleunigung.
		\item Der \textbf{Magentometer} misst die zwei-dimensionale Ausrichtung (Kompass) und stellt auch langsame Abweichungen, die der Gyro nicht messen kann, fest.
	\end{itemize}
	\item \textbf{"'LPS25H"'}\footcite{Class-Leading_Miniature_Pressure_Sensor_from_STMicroelectronics_Powers_New_Chapter_in_Mobile_Innovation_2015-03-30} (High precision pressure sensor)\\
	\textbf{Barometer:} Misst den Druck auf +/- 0.2\,mbar genau, damit kann die Höhe auf ca. 12\,m genau angenähert werden (was hauptsächlich auf die Abhängigkeit von Luftfeuchtigkeit und Temperatur zurückzuführen ist).
	\footcite{Barometrische_Hoehenformel__Wikipedia_2015-03-30}
\end{itemize}

\subsubsection{Entwicklung}
Anweisungen und Vorbereitungen für die Entwicklung der \textit{Crazyflie 2.0} finden sich im "`Getting started"'.\footcite{doc_crazyflie_dev:starting_Bitcraze_Wiki_2015-03-29}

Bitcraze stellt für die Entwicklung eine vorkonfigurierte \gls{vmLabel} zur Verfügung, auf der wesentliche Programme und Repositories bereits vorhanden sind.
\footcite{projects_virtualmachine_index_Bitcraze_Wiki_2015-03-30}
So entfällt die etwas aufwändige Installation. Dafür können Probleme mit den USB-Geräten auftreten. Alternativ können alle benötigten Ressourcen auch direkt eingerichtet werden.

Auch dabei ist das \textit{Crazyflie Client} Programm für \textit{control-}, \textit{log-} und \textit{bootload-}Aufgaben.
\footcite{doc_crazyflie_client_pycfclient_index_Bitcraze_Wiki_2015-03-30}

Folgendes Setup wurde für die Entwicklung verwendet:
\begin{itemize}
	\item Chip \textbf{STM32F405:} mit Firmware "`Crazyflie 2.0 2014.12.0"'\footcite{bitcraze_crazyflie-firmware_2015-03-30}
	\item Chip \textbf{nRF51822:} mit Firmware "`Version 1.1"'\footcite{bitcraze_crazyflie2-nrf-firmware_2015-03-30}
	\item \textbf{Crazyflie Client:} die Client Software "`Crazyflie PC client 2014.12.3"'\footcite{bitcraze_crazyflie-clients-python_2015-03-30}
\end{itemize}


\subsubsection{API}
% doc: http://wiki.bitcraze.se/doc:crazyflie:api:python:index
% examples: https://github.com/bitcraze/crazyflie-clients-python
Die Möglichkeiten der Python API sind auf der Seite "`The Crazyflie Python API"' genau beschrieben.\footcite{doc_crazyflie_api_python_index_Bitcraze_Wiki_2015-03-30}
Einleitende Beispiele stehen auf GitHub zur Verfügung.\footcite{crazyflie-clients-python_examples_crazyflie-clients-python_2015-03-30}


\subsubsection{Sensoren charakterisieren}


%%%

\section{Soll-Analyse}
\subsection{Gesten-Steuerbeschrieb}


%%%
